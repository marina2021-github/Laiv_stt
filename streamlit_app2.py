# requirements.txtì— ë‹¤ìŒ ì¶”ê°€ (Cloud í™˜ê²½ì´ë©´ ì‘ë™ ì—¬ë¶€ ë³´ì¥ ì•ˆ ë¨)
# ffmpeg-python
# ë§Œì•½ ì•ˆë˜ë©´ ë¡œì»¬ PCë‚˜ Dockerë¡œ ì‹¤í–‰ ê¶Œì¥

import streamlit as st
import tempfile
import os
from faster_whisper import WhisperModel

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="STT Demo: Whisper + Streamlit", layout="centered")

# íƒ€ì´í‹€ ë° ì†Œê°œ
st.title("ğŸ™ï¸ STT Demo: Whisper + Streamlit")
st.markdown("### ğŸ“¤ Upload Audio File")
st.markdown("Only .wav or .mp3 files")

# íŒŒì¼ ì—…ë¡œë“œ
uploaded_file = st.file_uploader("Drag and drop an audio file here", type=["wav", "mp3"])

# ëª¨ë¸ ì„¤ì • ì˜µì…˜
st.markdown("### âš™ï¸ Model Settings")
model_size = st.selectbox("Model", ["tiny", "base", "small", "medium", "large"], index=1)
language_option = st.selectbox("Language", ["Auto", "en", "ko", "ja", "zh", "fr", "de"], index=0)

# ëª¨ë¸ ë¡œë”© í•¨ìˆ˜
@st.cache_resource
def load_model(model_size):
    return WhisperModel(model_size, compute_type="float32")

# ë³€í™˜ ë²„íŠ¼
if uploaded_file and st.button("ğŸ§ Transcribe"):
    with st.spinner("Loading model and transcribing..."):
        # ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥
        with tempfile.NamedTemporaryFile(delete=False, suffix=".mp3") as tmp_file:
            tmp_file.write(uploaded_file.read())
            tmp_path = tmp_file.name

        # ëª¨ë¸ ë¡œë”©
        model = load_model(model_size)

        # ì–¸ì–´ ì„¤ì •
        lang_code = None if language_option == "Auto" else language_option

        try:
            # ì¶”ë¡ 
            segments, info = model.transcribe(tmp_path, language=lang_code)

            # ê²°ê³¼ ì¶œë ¥
            st.markdown("### ğŸ“ Transcription Result")
            full_text = " ".join([seg.text for seg in segments])
            st.text_area("Transcription", full_text, height=300)

        except Exception as e:
            st.error(f"Transcription failed: {e}")

        finally:
            os.remove(tmp_path)
